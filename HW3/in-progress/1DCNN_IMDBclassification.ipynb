{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 12:24:57.160318: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-04-25 12:24:57.160365: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train seq: 25000\n",
      "Test seq: 25000\n"
     ]
    }
   ],
   "source": [
    "n_words = 1000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=n_words)\n",
    "print('Train seq: {}'.format(len(X_train)))\n",
    "print('Test seq: {}'.format(len(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train example: \n",
      "[1, 14, 22, 16, 43, 530, 973, 2, 2, 65, 458, 2, 66, 2, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 2, 2, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2, 19, 14, 22, 4, 2, 2, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 2, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2, 2, 16, 480, 66, 2, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 2, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 2, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 2, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 2, 88, 12, 16, 283, 5, 16, 2, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n",
      "\n",
      "Test example: \n",
      "[1, 591, 202, 14, 31, 6, 717, 10, 10, 2, 2, 5, 4, 360, 7, 4, 177, 2, 394, 354, 4, 123, 9, 2, 2, 2, 10, 10, 13, 92, 124, 89, 488, 2, 100, 28, 2, 14, 31, 23, 27, 2, 29, 220, 468, 8, 124, 14, 286, 170, 8, 157, 46, 5, 27, 239, 16, 179, 2, 38, 32, 25, 2, 451, 202, 14, 6, 717]\n"
     ]
    }
   ],
   "source": [
    "print('Train example: \\n{}'.format(X_train[0]))\n",
    "print('\\nTest example: \\n{}'.format(X_test[0]))\n",
    "\n",
    "# Note: the data is already preprocessed (words are mapped to vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences with max_len\n",
    "max_len = 200\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 200, 50)           50000     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200, 50)           0         \n",
      "                                                                 \n",
      " conv1d (Conv1D)             (None, 198, 128)          19328     \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 128)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 250)               32250     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 250)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 251       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,829\n",
      "Trainable params: 101,829\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-25 12:25:00.965610: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-04-25 12:25:00.965653: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-04-25 12:25:00.965684: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (Willy): /proc/driver/nvidia/version does not exist\n",
      "2022-04-25 12:25:00.965941: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Define network architecture and compile\n",
    "model = Sequential()\n",
    "model.add(Embedding(n_words, 50, input_length=max_len))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv1D(128, 3, padding='valid', activation='relu', strides=1,))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(250, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',  optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [EarlyStopping(monitor='val_accuracy', patience=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.5640 - accuracy: 0.6844 - val_loss: 0.4124 - val_accuracy: 0.8142\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3903 - accuracy: 0.8256 - val_loss: 0.3419 - val_accuracy: 0.8522\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.3523 - accuracy: 0.8466 - val_loss: 0.3306 - val_accuracy: 0.8572\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.3295 - accuracy: 0.8592 - val_loss: 0.3211 - val_accuracy: 0.8648\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.3114 - accuracy: 0.8677 - val_loss: 0.3163 - val_accuracy: 0.8652\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.3004 - accuracy: 0.8738 - val_loss: 0.3158 - val_accuracy: 0.8616\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2933 - accuracy: 0.8759 - val_loss: 0.3119 - val_accuracy: 0.8638\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2860 - accuracy: 0.8812 - val_loss: 0.3096 - val_accuracy: 0.8680\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.2755 - accuracy: 0.8858 - val_loss: 0.3180 - val_accuracy: 0.8628\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2675 - accuracy: 0.8882 - val_loss: 0.3150 - val_accuracy: 0.8628\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 3s 11ms/step - loss: 0.2627 - accuracy: 0.8902 - val_loss: 0.3066 - val_accuracy: 0.8670\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe460ccd850>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 100\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=n_epochs, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 975us/step - loss: 0.3017 - accuracy: 0.8731\n",
      "\n",
      "Accuracy on test set: 0.8731200098991394\n"
     ]
    }
   ],
   "source": [
    "print('\\nAccuracy on test set: {}'.format(model.evaluate(X_test, y_test)[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
